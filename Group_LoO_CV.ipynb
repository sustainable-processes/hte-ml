{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-one-group-out Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required packages \n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# for RF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# for svr\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# for adaboost\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#for GP\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF,Matern, ConstantKernel as C\n",
    "\n",
    "# for the NN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inputs and the outputs ready - the features can be generated using the separate file Preprocessing.ipynb\n",
    "\n",
    "input = data_2_sterimol\n",
    "#input = np.append(input,dft_data,axis=1)\n",
    "#input = np.append(input,fp_pca_data,axis=1)\n",
    "#input = np.append(input,dataset_one_hot,axis=1)\n",
    "#input = np.append(input,NBO_data,axis=1)\n",
    "#input = np.append(input,chelpg_data,axis=1)\n",
    "#input = np.append(input,vol_bur,axis=1)\n",
    "#input = np.append(input,n_proton,axis=1)\n",
    "# input = np.append(input,data_only_R_sterimol,axis=1)\n",
    "# input = np.append(input,chelpg_data,axis=1)\n",
    "\n",
    "input = np.array(input)\n",
    "print('total_input shape:',input.shape)\n",
    "\n",
    "output = dataset['Yield']\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = dataset.Ligand\n",
    "#groups = np.array(groups).reshape(-1,1)\n",
    "print(groups.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data and conduct the modelling & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# read which ligand belongs to which group\n",
    "groups = dataset.Ligand\n",
    "\n",
    "linear_rmse_list = []\n",
    "\n",
    "rmse_list = []\n",
    "rmse_list_train = []\n",
    "mae_list = []\n",
    "\n",
    "gp_rmse_list = []\n",
    "gp_rmse_list_train = []\n",
    "\n",
    "svr_rmse_list = []\n",
    "svr_rmse_list_train = []\n",
    "\n",
    "adaboost_rmse_list = []\n",
    "adaboost_rmse_list_train = []\n",
    "\n",
    "nn_rmse_list = []\n",
    "nn_rmse_list_train = []\n",
    "\n",
    "for train_index, test_index in logo.split(input, output, groups=groups):\n",
    "    \n",
    "    train_shape = input[train_index]\n",
    "    test_shape = input[test_index]\n",
    "    \n",
    "    print(train_shape.shape, test_shape.shape)\n",
    "    print(test_index)\n",
    "    \n",
    "    \n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(input[train_index], output[train_index])\n",
    "    linear_test_predictions = linear_regressor.predict(input[test_index])\n",
    "    linear_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], linear_test_predictions)))\n",
    "\n",
    "    \n",
    "    rf_regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "    rf_regressor.fit(input[train_index], output[train_index])\n",
    "    rf_test_predictions = rf_regressor.predict(input[test_index])\n",
    "    rf_train_predictions = rf_regressor.predict(input[train_index])\n",
    "\n",
    "    mae_list.append(np.sqrt(metrics.mean_absolute_error(output[test_index], rf_test_predictions)))\n",
    "    rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], rf_test_predictions)))\n",
    "    # get train rmse\n",
    "    rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], rf_train_predictions)))\n",
    "    \n",
    "    print('RF Cylce done')\n",
    "    \n",
    "    #GP\n",
    "    kernel =  C(0.1, (1e-5, 1e2)) * RBF(100, (1e-3, 1e5))+ RBF(12, (1e-3, 1e5)) +RBF(1, (1e-3, 1e3))\n",
    "\n",
    "    gp = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=3)\n",
    "    gp.fit(input[train_index], output[train_index])\n",
    "    \n",
    "    gp_test_predictions, MSE = gp.predict(input[test_index], return_std=True)\n",
    "    gp_test_predictions_train, MSE_train = gp.predict(input[train_index], return_std=True)\n",
    "    \n",
    "    gp_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], gp_test_predictions)))\n",
    "    gp_rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], gp_test_predictions_train)))\n",
    "\n",
    "    print('GP Cylce done')\n",
    "    \n",
    "    svr = SVR(kernel='linear')\n",
    "    svr.fit(input[train_index], output[train_index])\n",
    "    \n",
    "    svr_test_predictions = svr.predict(input[test_index])\n",
    "    svr_test_predictions_train = svr.predict(input[train_index])\n",
    "    \n",
    "    svr_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], svr_test_predictions)))\n",
    "    svr_rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], svr_test_predictions_train)))\n",
    "    \n",
    "    \n",
    "    print('SVR Cylce done')\n",
    "\n",
    "    \n",
    "    adaboost = AdaBoostRegressor(random_state=0, n_estimators=2000)\n",
    "    adaboost.fit(input[train_index], output[train_index])\n",
    "    \n",
    "    adaboost_test_predictions = adaboost.predict(input[test_index])\n",
    "    adaboost_test_predictions_train = adaboost.predict(input[train_index])\n",
    "    \n",
    "    adaboost_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], adaboost_test_predictions)))\n",
    "    adaboost_rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], adaboost_test_predictions_train)))\n",
    "    \n",
    "    print('adaboost Cylce done')\n",
    "    \n",
    "    # NN\n",
    "    input_dimension = 146\n",
    "    \n",
    "    def build_model():\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(1)])\n",
    "    \n",
    "      optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "      model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "      return model\n",
    "    \n",
    "    model = build_model()\n",
    "    EPOCHS = 1000\n",
    "    history = model.fit(input[train_index], output[train_index],epochs=EPOCHS, validation_split = 0.3, verbose=0)#,callbacks=[tfdocs.modeling.EpochDots()])\n",
    "    nn_test_predictions = model.predict(input[test_index])#.flatten())\n",
    "    nn_train_predictions = model.predict(input[train_index])#.flatten())\n",
    "\n",
    "    \n",
    "    nn_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], nn_test_predictions)))\n",
    "    nn_rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], nn_train_predictions)))\n",
    "    print('NN Cylce done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_rmse = np.array(linear_rmse_list)\n",
    "linear_rmse_average = np.average(linear_rmse)\n",
    "linear_rmse_stdev = np.std(linear_rmse)\n",
    "print('The Linear Model average RMSE of group cross validations is:',linear_rmse_average, '+-' ,linear_rmse_stdev)\n",
    "\n",
    "rmse = np.array(rmse_list)\n",
    "rmse_average = np.average(rmse)\n",
    "rf_rmse_stdev = np.std(rmse_list)\n",
    "\n",
    "print('The Random Forest average RMSE of the group cross validations is:',rmse_average, '+-' ,rf_rmse_stdev)\n",
    "\n",
    "gp_rmse = np.array(gp_rmse_list)\n",
    "gp_rmse_average = np.average(gp_rmse)\n",
    "gp_rmse_stdev = np.std(gp_rmse)\n",
    "\n",
    "print('The Gaussian Process average RMSE of group cross validations is:',gp_rmse_average, '+-' ,gp_rmse_stdev)\n",
    "\n",
    "nn_rmse = np.array(nn_rmse_list)\n",
    "nn_rmse_average = np.average(nn_rmse)\n",
    "nn_std_rmse = np.std(nn_rmse)\n",
    "\n",
    "print('The Neural Net average RMSE of 10 cross validations is:',nn_rmse_average,'+-',nn_std_rmse)\n",
    "\n",
    "svr_rmse = np.array(svr_rmse_list)\n",
    "svr_rmse_average = np.average(svr_rmse)\n",
    "svr_rmse_stdev = np.std(svr_rmse)\n",
    "\n",
    "print('The SVR average RMSE of group cross validations is:',svr_rmse_average, '+-' ,svr_rmse_stdev)\n",
    "\n",
    "adaboost_rmse = np.array(adaboost_rmse_list)\n",
    "adaboost_rmse_average = np.average(adaboost_rmse)\n",
    "adaboost_rmse_stdev = np.std(adaboost_rmse)\n",
    "\n",
    "print('The adaboost average RMSE of group cross validations is:',adaboost_rmse_average, '+-' ,adaboost_rmse_stdev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for the RF\n",
    "\n",
    "x_axis = np.arange(1,(len(rmse)+1))\n",
    "\n",
    "plt.title(label=\"Random Forest LOGO single splits - Train RMSE\")\n",
    "#plt.figsize(20,10)\n",
    "plt.bar(x_axis, rmse_list_train)\n",
    "#plt.scatter(x_axis, rmse)\n",
    "plt.xlabel('splits')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim(0,0.05,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for the RF\n",
    "\n",
    "x_axis = np.arange(1,(len(rmse)+1))\n",
    "\n",
    "plt.title(label=\"Random Forest LOGO single splits - Test RMSE\")\n",
    "#plt.figsize(20,10)\n",
    "plt.bar(x_axis, rmse)\n",
    "#plt.scatter(x_axis, rmse)\n",
    "plt.xlabel('splits')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim(0,0.7,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('Random Forest LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(gp_rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, gp_rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, gp_rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('Gaussian Process LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(svr_rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, svr_rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, svr_rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('SVR LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(adaboost_rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, adaboost_rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, adaboost_rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('adaboost LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(nn_rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, nn_rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, nn_rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('Neural Net LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
