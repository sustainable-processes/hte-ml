{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave one out Group Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required packages \n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# for RF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# for svr\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# for adaboost\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#for GP\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF,Matern, ConstantKernel as C\n",
    "\n",
    "# for the NN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "\n",
    "#install package for excel support\n",
    "#!pip install xlrd --user\n",
    "import xlrd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inputs and the outputs ready\n",
    "\n",
    "input = data_2_sterimol\n",
    "#input = np.append(input,dft_data,axis=1)\n",
    "#input = np.append(input,fp_pca_data,axis=1)\n",
    "#input = np.append(input,dataset_one_hot,axis=1)\n",
    "#input = np.append(input,NBO_data,axis=1)\n",
    "#input = np.append(input,chelpg_data,axis=1)\n",
    "#input = np.append(input,vol_bur,axis=1)\n",
    "#input = np.append(input,n_proton,axis=1)\n",
    "# input = np.append(input,data_only_R_sterimol,axis=1)\n",
    "# input = np.append(input,chelpg_data,axis=1)\n",
    "\n",
    "input = np.array(input)\n",
    "print('total_input shape:',input.shape)\n",
    "\n",
    "output = dataset['Yield']\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = dataset.Ligand\n",
    "#groups = np.array(groups).reshape(-1,1)\n",
    "print(groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing all models with the same split\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# read which ligand belongs to which group\n",
    "groups = dataset.Ligand\n",
    "\n",
    "linear_rmse_list = []\n",
    "\n",
    "rmse_list = []\n",
    "rmse_list_train = []\n",
    "mae_list = []\n",
    "\n",
    "gp_rmse_list = []\n",
    "gp_rmse_list_train = []\n",
    "\n",
    "svr_rmse_list = []\n",
    "svr_rmse_list_train = []\n",
    "\n",
    "adaboost_rmse_list = []\n",
    "adaboost_rmse_list_train = []\n",
    "\n",
    "nn_rmse_list = []\n",
    "nn_rmse_list_train = []\n",
    "\n",
    "for train_index, test_index in logo.split(input, output, groups=groups):\n",
    "    \n",
    "    train_shape = input[train_index]\n",
    "    test_shape = input[test_index]\n",
    "    \n",
    "    print(train_shape.shape, test_shape.shape)\n",
    "    print(test_index)\n",
    "    \n",
    "    \n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(input[train_index], output[train_index])\n",
    "    linear_test_predictions = linear_regressor.predict(input[test_index])\n",
    "    linear_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], linear_test_predictions)))\n",
    "\n",
    "    \n",
    "    #print(\"Train:\", train_index,\"Validation:\",test_index)\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "    rf_regressor.fit(input[train_index], output[train_index])\n",
    "    rf_test_predictions = rf_regressor.predict(input[test_index])\n",
    "    rf_train_predictions = rf_regressor.predict(input[train_index])\n",
    "\n",
    "    mae_list.append(np.sqrt(metrics.mean_absolute_error(output[test_index], rf_test_predictions)))\n",
    "    rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], rf_test_predictions)))\n",
    "    # get train rmse\n",
    "    rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], rf_train_predictions)))\n",
    "    \n",
    "    print('RF Cylce done')\n",
    "    \"\"\"\n",
    "    #GP\n",
    "    kernel =  C(0.1, (1e-5, 1e2)) * RBF(100, (1e-3, 1e5))+ RBF(12, (1e-3, 1e5)) +RBF(1, (1e-3, 1e3))\n",
    "\n",
    "    gp = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=3)\n",
    "    gp.fit(input[train_index], output[train_index])\n",
    "    \n",
    "    gp_test_predictions, MSE = gp.predict(input[test_index], return_std=True)\n",
    "    gp_test_predictions_train, MSE_train = gp.predict(input[train_index], return_std=True)\n",
    "    \n",
    "    gp_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], gp_test_predictions)))\n",
    "    gp_rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], gp_test_predictions_train)))\n",
    "\n",
    "    print('GP Cylce done')\n",
    "    \n",
    "    svr = SVR(kernel='linear')\n",
    "    svr.fit(input[train_index], output[train_index])\n",
    "    \n",
    "    svr_test_predictions = svr.predict(input[test_index])\n",
    "    svr_test_predictions_train = svr.predict(input[train_index])\n",
    "    \n",
    "    svr_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], svr_test_predictions)))\n",
    "    svr_rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], svr_test_predictions_train)))\n",
    "    \n",
    "    \n",
    "    print('SVR Cylce done')\n",
    "\n",
    "    \n",
    "    adaboost = AdaBoostRegressor(random_state=0, n_estimators=2000)\n",
    "    adaboost.fit(input[train_index], output[train_index])\n",
    "    \n",
    "    adaboost_test_predictions = adaboost.predict(input[test_index])\n",
    "    adaboost_test_predictions_train = adaboost.predict(input[train_index])\n",
    "    \n",
    "    adaboost_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], adaboost_test_predictions)))\n",
    "    adaboost_rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], adaboost_test_predictions_train)))\n",
    "    \n",
    "    print('adaboost Cylce done')\n",
    "    \n",
    "    # NN\n",
    "    input_dimension = 146\n",
    "    \n",
    "    def build_model():\n",
    "      model = keras.Sequential([\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(10, activation='relu', input_shape=[150,input_dimension]),\n",
    "        layers.Dense(1)])\n",
    "    \n",
    "      optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "      model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "      return model\n",
    "    \n",
    "    model = build_model()\n",
    "    EPOCHS = 1000\n",
    "    history = model.fit(input[train_index], output[train_index],epochs=EPOCHS, validation_split = 0.3, verbose=0)#,callbacks=[tfdocs.modeling.EpochDots()])\n",
    "    nn_test_predictions = model.predict(input[test_index])#.flatten())\n",
    "    nn_train_predictions = model.predict(input[train_index])#.flatten())\n",
    "\n",
    "    \n",
    "    nn_rmse_list.append(np.sqrt(metrics.mean_squared_error(output[test_index], nn_test_predictions)))\n",
    "    nn_rmse_list_train.append(np.sqrt(metrics.mean_squared_error(output[train_index], nn_train_predictions)))\n",
    "    print('NN Cylce done')\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_rmse = np.array(linear_rmse_list)\n",
    "linear_rmse_average = np.average(linear_rmse)\n",
    "linear_rmse_stdev = np.std(linear_rmse)\n",
    "print('The Linear Model average RMSE of group cross validations is:',linear_rmse_average, '+-' ,linear_rmse_stdev)\n",
    "\n",
    "rmse = np.array(rmse_list)\n",
    "rmse_average = np.average(rmse)\n",
    "rf_rmse_stdev = np.std(rmse_list)\n",
    "\n",
    "print('The Random Forest average RMSE of the group cross validations is:',rmse_average, '+-' ,rf_rmse_stdev)\n",
    "\n",
    "gp_rmse = np.array(gp_rmse_list)\n",
    "gp_rmse_average = np.average(gp_rmse)\n",
    "gp_rmse_stdev = np.std(gp_rmse)\n",
    "\n",
    "print('The Gaussian Process average RMSE of group cross validations is:',gp_rmse_average, '+-' ,gp_rmse_stdev)\n",
    "\n",
    "nn_rmse = np.array(nn_rmse_list)\n",
    "nn_rmse_average = np.average(nn_rmse)\n",
    "nn_std_rmse = np.std(nn_rmse)\n",
    "\n",
    "print('The Neural Net average RMSE of 10 cross validations is:',nn_rmse_average,'+-',nn_std_rmse)\n",
    "\n",
    "svr_rmse = np.array(svr_rmse_list)\n",
    "svr_rmse_average = np.average(svr_rmse)\n",
    "svr_rmse_stdev = np.std(svr_rmse)\n",
    "\n",
    "print('The SVR average RMSE of group cross validations is:',svr_rmse_average, '+-' ,svr_rmse_stdev)\n",
    "\n",
    "adaboost_rmse = np.array(adaboost_rmse_list)\n",
    "adaboost_rmse_average = np.average(adaboost_rmse)\n",
    "adaboost_rmse_stdev = np.std(adaboost_rmse)\n",
    "\n",
    "print('The adaboost average RMSE of group cross validations is:',adaboost_rmse_average, '+-' ,adaboost_rmse_stdev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''# Getting the metrics for the RF\n",
    "\n",
    "x_axis = np.arange(1,(len(rmse)+1))\n",
    "\n",
    "plt.title(label=\"Random Forest LOGO single splits - Train RMSE\")\n",
    "#plt.figsize(20,10)\n",
    "plt.bar(x_axis, rmse_list_train)\n",
    "#plt.scatter(x_axis, rmse)\n",
    "plt.xlabel('splits')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim(0,0.05,0.1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Getting the metrics for the RF\n",
    "\n",
    "x_axis = np.arange(1,(len(rmse)+1))\n",
    "\n",
    "plt.title(label=\"Random Forest LOGO single splits - Test RMSE\")\n",
    "#plt.figsize(20,10)\n",
    "plt.bar(x_axis, rmse)\n",
    "#plt.scatter(x_axis, rmse)\n",
    "plt.xlabel('splits')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim(0,0.7,0.1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('Random Forest LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(gp_rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, gp_rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, gp_rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('Gaussian Process LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(svr_rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, svr_rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, svr_rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('SVR LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(adaboost_rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, adaboost_rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, adaboost_rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('adaboost LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,(len(nn_rmse)+1))\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, nn_rmse_list_train, width, label='Train_RMSE',color='orange')\n",
    "rects2 = ax.bar(x + width/2, nn_rmse, width, label='Test_RMSE',color='dodgerblue')\n",
    "ax.set_title('Neural Net LOGO single splits')\n",
    "ax.set_xlabel('LoGo folds')\n",
    "ax.set_ylabel('RMSE')\n",
    "\n",
    "#ax.set_xticks(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_similarity_between_train_test = [0.21907455, 0.20045429, 0.47844082, 0.32581347, 0.30365131, 0.39116696,\n",
    " 0.40184797, 0.27870821, 0.30368409, 0.15305065, 0.17294601, 0.34416853,\n",
    " 0.27671535, 0.32800863, 0.20900604, 0.42864673, 0.4171398,  0.41046084,\n",
    " 0.35870729, 0.37524933, 0.40358373, 0.23047282, 0.35161783, 0.35729539,\n",
    " 0.3551004,  0.41660296, 0.26710844, 0.32726295, 0.33613512, 0.28820937,\n",
    " 0.34080953]\n",
    "\n",
    "avg_similarity_between_train_test = np.array(avg_similarity_between_train_test).reshape(-1,1)\n",
    "print(avg_similarity_between_train_test.shape)\n",
    "adaboost_rmse = adaboost_rmse.reshape(-1,1)\n",
    "print(adaboost_rmse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(label=\"RF\")\n",
    "rmse = rmse.reshape(-1,1)\n",
    "plt.scatter(avg_similarity_between_train_test, rmse)\n",
    "plt.xlabel('avg_tanimoto_similarity_between_train_test')\n",
    "plt.ylabel('adaboost_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(label=\"GP\")\n",
    "rmse = rmse.reshape(-1,1)\n",
    "plt.scatter(avg_similarity_between_train_test, gp_rmse)\n",
    "plt.xlabel('avg_tanimoto_similarity_between_train_test')\n",
    "plt.ylabel('GP_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(label=\"NN\")\n",
    "rmse = rmse.reshape(-1,1)\n",
    "plt.scatter(avg_similarity_between_train_test, nn_rmse)\n",
    "plt.xlabel('avg_tanimoto_similarity_between_train_test')\n",
    "plt.ylabel('NN_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(label=\"SVR\")\n",
    "rmse = rmse.reshape(-1,1)\n",
    "plt.scatter(avg_similarity_between_train_test, svr_rmse)\n",
    "plt.xlabel('avg_tanimoto_similarity_between_train_test')\n",
    "plt.ylabel('SVR_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's overalay all data\n",
    "\n",
    "\n",
    "plt.title(label=\"All models\")\n",
    "plt.scatter(avg_similarity_between_train_test, adaboost_rmse, label='Adaboost')\n",
    "plt.scatter(avg_similarity_between_train_test, rmse, label='Random Forest')\n",
    "plt.scatter(avg_similarity_between_train_test, gp_rmse, label='Gaussian Process')\n",
    "plt.scatter(avg_similarity_between_train_test, svr_rmse, label='Supported Vector Regression')\n",
    "plt.scatter(avg_similarity_between_train_test, nn_rmse, label='Neural Net')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Average similarity between train and test data')\n",
    "plt.ylabel('Model RMSE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a line plot of the average values of the five models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adaboost_rmse.shape)\n",
    "print(rmse.shape)\n",
    "print(gp_rmse.shape)\n",
    "print(svr_rmse.shape)\n",
    "print(nn_rmse.shape)\n",
    "\n",
    "gp_rmse = gp_rmse.reshape(-1,1)\n",
    "svr_rmse = svr_rmse.reshape(-1,1)\n",
    "nn_rmse = nn_rmse.reshape(-1,1)\n",
    "\n",
    "print(gp_rmse.shape)\n",
    "print(svr_rmse.shape)\n",
    "print(nn_rmse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_average = np.append(adaboost_rmse, rmse, axis = 1)\n",
    "model_average = np.append(model_average, gp_rmse, axis = 1)\n",
    "model_average = np.append(model_average, svr_rmse, axis = 1)\n",
    "model_average = np.append(model_average, nn_rmse, axis = 1)\n",
    "\n",
    "print(model_average.shape)\n",
    "print(model_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_average_calculated = np.mean(model_average, axis=1)\n",
    "print(model_average_calculated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(avg_similarity_between_train_test,model_average_calculated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
